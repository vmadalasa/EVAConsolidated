# -*- coding: utf-8 -*-
"""S10_Assignment_with_ReduceLR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tPnSVYYDogj2tv3D9dDWO5P96DZB5OWL

# Memory Information
"""

import psutil
def get_size(bytes, suffix="B"):
    factor = 1024
    for unit in ["", "K", "M", "G", "T", "P"]:
        if bytes < factor:
            return f"{bytes:.2f}{unit}{suffix}"
        bytes /= factor
print("="*40, "Memory Information", "="*40)
svmem = psutil.virtual_memory()
print(f"Total: {get_size(svmem.total)}") ; print(f"Available: {get_size(svmem.available)}")
print(f"Used: {get_size(svmem.used)}") ; print(f"Percentage: {svmem.percent}%")

"""# GPU Information"""

!pip install albumentations==0.4.5 --quiet

!nvidia-smi

device = 'cuda'
from CusResNet import CusResNet18

model = CusResNet18().to(device)

from augmentation import CIFAR10_AlbumTrans
from data import CIFAR10DataLoader
from data_summary import model_summary, display

trans = CIFAR10_AlbumTrans()
data = CIFAR10DataLoader(trans, batch_size=128)
train_loader, test_loader = data.get_loaders()
display(train_loader, 64)

model_summary(model)

import torch
import torch.nn as nn
import torch.optim as optim
from find_lr import LRFinder

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=1e-7, momentum= 0.9)
lr_finder = LRFinder(model, optimizer, criterion, device= 'cuda')

lr_finder.range_test(train_loader, end_lr=100, num_iter=100, step_mode="exp") #Fast AI Approach

lr_finder.plot()

print('Least Lost as per Fast AI: ', min(lr_finder.history['loss']))
best_lr = lr_finder.history['lr'][lr_finder.history['loss'].index(min(lr_finder.history['loss']))]
print('Best lr as per Fast AI: ', best_lr)

lr_finder.reset()

from test import Test
from train import Train
from torch.optim.lr_scheduler import ReduceLROnPlateau

optimizer = optim.SGD(model.parameters(), lr=best_lr, momentum= 0.9)
test = Test(model, device, test_loader)
train = Train(model, device, train_loader, optimizer)
scheduler = ReduceLROnPlateau(optimizer, mode= 'max', patience= 2)

lr_list = []
epochs = 50
print('='*20 + 'START' + '='*20)
for epoch in range(epochs):
  print('='*20 + f' EPOCH: {epoch+1} ' + '='*20)
  train.train(epoch)
  lr_list.append(optimizer.param_groups[0]['lr'])
  test.test()
  scheduler.step(test.test_acc[-1]) #Have to give the val_loss or val_accuracy here. The metric on which we can to check and

import plot
from plot import mis, gen_cam, plot_pred_cam, plot_act_cam

best_model = CusResNet18().to(device)
best_model.load_state_dict(torch.load('/content/classifier.pt'))
best_model.eval()
print('Best Model Loaded!')

mis(best_model, device, test_loader, 36)

layers = ['layer1', 'layer2', 'layer3', 'layer4',]
for layer in layers:
  gen_cam(best_model, layer) #GradCAM for Misclassified w.r.t Predicted Class
  gen_cam(best_model, layer, class_idx= plot.true_list) #GradCAM for Misclassified w.r.t Actual Class

plot_pred_cam(36, 4)

plot_act_cam(36,4)

from graphs import acc_loss, testvtrain, class_acc

acc_loss(train, test)

testvtrain(train, test)

class_acc(model, device, test_loader)

optimizer.param_groups[0]['lr']

len(lr_list)

set_lr = set(lr_list)

len(set_lr)

set_lr

import matplotlib.pyplot as plt

plt.plot(lr_list)
plt.title('Change in Learnig Rate')
plt.xlabel('epochs')
plt.ylabel('Learning Rate')